llm_configs:
  general_configs:
    max_token_length: 24064
    temperature: 1
    top_p: 1
  llama-3-8b:
    model: "llama-3-8b"
    model_path: "/home/cshdtian/pretrained_models/LargeLanguageModels/llama-3/models--meta-llama--Meta-Llama-3-8B-Instruct/snapshots/e1945c40cd546c78e41f1151f4db032b271faeaa"
  qwen-2.5-7b:
    model: "Qwen/Qwen2.5-7B-Instruct"
    model_path: "/home/cshdtian/pretrained_models/LargeLanguageModels/Qwen-2.5-7b/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28"
  qwen-2.5-14b:
    model: "Qwen/Qwen2.5-14B-Instruct"
    model_path: None
  qwen-2.5-72b:
    model: "Qwen/Qwen2.5-72B-Instruct"
    model_path: None